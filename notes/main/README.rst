Main Memory
~~~~~~~~~~~

Background
==========

Basic Hardware
--------------

Main memory and registers are the only general-purpose storage directly
accessible by the CPU.  Registers can be accessed in one clock cycle.  Main
memory takes several cycles because data must travel along the CPU bus.
Because of that, the CPU may need to **stall**.  The remedy is to add an
intermediary storage called a **cache** which can retrieve blocks of data from
memory, then load them into registers as needed.

Protection also needs to be enabled; we must make sure that a user process can
only access its allocated memory. For that we need to ensure each process has
its own memory space.  We do this using a **base register** and a **limit
register**.  The base register points to the first address of a memory segment,
and the limit register the last address.  These registers are checked for each
memory retrieval, and if the memory is not in bounds, then a trap is sent to
the OS.

Address Binding
---------------

Processes must be loaded into memory before they can be executed.  Process
waiting to be brought into memory are put into an **input queue**.  A compiler
typically **binds** addresses to relocatable addresses (+12).  The linkage
editor or loader binds the relocatable address to absolute addresses
(0x003E4D).

Binding can be done at different times:

  * *Compile time*. **Absolute code** can be generated if we know exactly
    where in memory it will be placed. MS-DOS .COM-format programs are bound
    at compile time.

  * *Load time*. **Relocatable code** is generated by the compiler, which 
    be bound once the program loads.  Binding is done by the loader.

  * *Execution time*. If a process is enabled to move around in memory, then
    it must be bound at execution time.  Most OSs use this method.


Logical vs. Physical Addresses
------------------------------

Addresses generated by the CPU are generally called **logical addresses**,
whereas those from the viewpoint of memory are called **physical addresses**.
Logical addresses are also called **virtual addresses**.  All logical addresses
consistute what is called a **logical address space**, whereas physical
addresses constitute a **physical address space**.  

Address bindings differ between the CPU and main memory during execution time.
To translate logical to physical addresses, a **memory management unit (MMU)**
is used. The MMU adds the base address in a **relocation register** and adds it
to the offset of the logical address to produce a physical address.  These
physical addresses can be loaded into the **memory-address register**  of the
memory to indicate its position.

Thus user programs never see real physical addresses. 

Dynamic Loading and Linking
---------------------------

**Dynamic loading** only loads routines once called.  The main program is
loaded into memory and executed at start of execution; but only when a routine
needs to be called is it loaded into memory.  This increases memory-space
utilization. 

**Dynamic linking** links system libraries to user programs at run-time.  This
enables only one copy of system libraries to exist in memory.  **Static
linking** links at load time, which means copies of system library code exist
in each process (but not in the objects).  In either case, until run-time, the
program has undefined symbols.   Dynamic linking includes a **stub** in the
image.  A stub is a piece of code which indicates how to find the library code
if it is not already loaded.

Each program must have a copy of its library available on the system to be
linked at run-time.  Sometimes updates to libraries are done; to prevent
library updates from breaking old code, the library version numbers are
maintained, and the program keeps track of the version of the library run.
Such libraries are called **shared libraries**.  You can find them in ``/lib``
and ``/usr/lib``, and generally they have ``.so`` extensions (which stands for
"shared object"). 

Swapping
========

If memory is full, the OS may **swap** processes out to a **backing store** to
make room for new ones.  Typically the backing store is a fast disk (an SSD is
ideal). This makes it possible for the physical address space of the system to
exceed the actual physical memory of the system.

The system maintains a **ready queue** of all processes whose memory images are
on the backing store or in memory and are ready to run. Whenever the scheduler
decides to execute a process, it calls the dispatcher, which checks to whether
the next process in the queue is in memory. If not, and there is no free
memory, the dispatcher swaps a process currently in memory out for the 
next ready process.

Context-switch time for swapping is high.  A 200MB process to be swapped in
from a hard disk with a 50MB transfer rate would take 4 seconds.  If we want to
swap a process, we should ensure it is idle, and in particular not waiting for
any I/O.  If we do want to swap in processes waiting for I/O, we must load the
I/O data into an OS buffer to be loaded into the process once it is swapped in.
This uses what is called **double buffering**, and requires overhead.  We must
now copy kernel-memory data into user-memory so the user process to access it.

Swapping is only used when the amount of free memory is low.

Contiguous Memory Allocation
============================

**Contiguous memory allocation** allocates each process in a single section
of memory that is contiguous to the section containing the next process. In
other words, processes are side-by-side in memory.

Memory Protection
-----------------

To protect memory, we can use the base and limit registers.  If a process
wishes to access memory, check to see if it is inside the bounds of these
registers.

This scheme allows for the OS size to change.  This flexibility may be
needed, in particular for modular kernels.  Device drivers may need to be
inserted or removed.  Such code is called **transient** OS code.

Memory Allocation
-----------------

One of the simplest ways to allocate memory is to do so in multiple fixed-size
**partitions**.  Each partition may contain one process.  In this
**multiple-partition method**, once a process is ready to run, a partition is
selected for it to be loaded into.

In a **variable-partition** scheme, the OS keeps a table indicating which parts
of memory are available and which are occupied.  Free memory segments form what
are called **holes**.  At any given time, the OS has an input queue and list of
holes.  The OS can order the processes according to a scheduling algorithm.
When a process is fit into a hole, memory is divided into two parts: the part
allocated for the process, and the remainder, which forms a smaller hole.  If
two holes are found to be adjacent, they are combined to form a larger hole.
This continues until there is no hold large enough to fit the next process, in
which case it must select another, or else wait until one becomes available.

This procedure is an instance of the **dynamic storage-allocation problem**;
there are several solutions:

  * **First fit**.  Find the first hole large enough. Fast and simple.

  * **Best fit**. Find the smallest hole which is large enough. We must
    search the entire list to find the maximin.

  * **Worst fit**. Find the largest hole. We must search the entire list
    to find the maximum.

First fit and best fit are better than worst fit in terms of decreasing time
and increasing storage utilization.  First fit is faster than best fit. 

Fragmentation
-------------

All strategies, in particular first fit and best fit, suffer from **external
fragmentation**--having small-sized non-contiguous holes which no process can
fit into.  To solve this, one can **defragment** memory or use **compaction**,
but it is expensive to move processes around in memory like this.

External fragmentation can have a drastic effect on memory utilization.
Analyses of first fit reveal that given *N* allocated blocks, another .5 *N*
blocks will be lost to fragmentation.  That is, nearly one-third of memory may
become unusable (called the **50-percent rule**).

Suppose we allocate for 0xFFFD bytes from a 0xFFFF memory hole. Then we are
left with 0x0002 bytes, but this requires more memory to keep track of than
exists in the hole.  To avoid this, we may choose to break memory into
fixed-size blocks and choose to allocate memory in blocks.  However then
memory may suffer from **internal fragmentation** from the leftover, unused
memory within a block.

One solution to fragmentation is to allow the logical address space to be
noncontiguous, thus allowing a process in physical memory to be allocated
wherever memory is available.

Segmentation
------------

**Segmentation** is a memory-management scheme that breaks memory into
purpose-driven segments: the main program, symbol table, stack, subroutines,
etc.  Then the program can refer to addresses by a segment name and an offset.
Segment names can be mapped to natural numbers.  A logical address can
therefore consist of a two-tuple, <n, m> where n is the segment number, and m
is an offset.  Normally when a program is compiled, the compiler constructs
segments.

The C compiler creates segments for code (text), globals (data), heap, stack,
and the C standard library.  Libraries linked during compile time might be
assigned their own segments. The loader assigns these segments numbers.


Segmentation Hardware
---------------------

We must map two-dimensional user addresses to one-dimensional physical
addresses, so we use a **segment table**, with each entry having a **segment
base** and a **segment limit**.  The base has the base address, the limit
has the size.  (Registers/caches?) 


Paging
======

**Paging** breaks physical memory into equal-sized units called **blocks** and
logical memory into same-sized units called **pages**.  When a process is to be
executed, pages are loaded onto the appropriate memory frames.  This means that
a logical address space is completely separated from the physical address
space, so a process could have a 64-bit address space even though the system
has less than 2^64 bytes of physical memory. 

Every address generated by the CPU is divided into two parts, a **page number**
*p* and a **page offset** (d).  Any address can be represented as a two-tuple
(p, d). The page number is used as an index to a **page table**. The page table
contains the base address of each page in physical memory.  The base address
combines with the page offset to yield the physical address.

Page size is defined by hardware.  The size of a page is a power of 2.  In
modern machines, it is between 512 bytes and 1 GB.  The typical size for modern
Linux machines is 4K.  You can get page size using the command ``getconf
PAGESIZE`` or by the system call ``getpagesize()``. 

If the size of the logical address space is 2^m, and a page size is 2^n bytes,
then the m-n bits of the logical address designate the page number, and the n
low-order bits designate the page offset.  This is because (2^m / 2^n), that is
the total number of pages, is 2^(m-n).  Since the page size is 2^n itself, we
need n bytes to describe an address within a page. 

Hardware Support
----------------

Each OS has its own methods for storing page tables.  Some have a per-process
page table.  A pointer to the page table is stored with other register values
in the PCB.  When the dispatcher starts a process, it loads the user registers
and defines the correct hardware page-table values from the stored user
page table.  

Other OSs have just one page table. In the simplest case, it is implemented as
a set of dedicated registers.  The use of registers is acceptable if the page
table is small (2^8 entries).  Most contemporary computers allow the page table
to be large; for these computers, the page table is kept in main memory, and a
**page-table base register** points to it.  Changing page tables requires
changing just this register, which reduces context-switch time.

The problem with this is the time required to access a memory location.  It
requires two memory accesses; one to look up the physical address in the page
table, then the other to access that address.  The solution to this is to use a
small, fast lookup hardware cache called a **translation look-aside buffer**
(TLB).  It is associative, high-speed memory (associative means containing
key-value pairs).  The TLB stores page numbers as keys and returns frame
numbers as values.  Lookups can be performed within the instruction pipeline,
but to support that the TLB must be kept small, typically between 2^5 and 2^10
entries.  Once the lookup returns a succeeds, the frame number is combined with
the page offset to access the address.

If a page is not in the TLB, this constitutes a **TLB miss**.  In this case,
a memory reference to the page must be made.  This may be done automatically
in hardware.  If the TLB is full, an existing entry must be replaced. Some
can be made irreplaceable (**wired down**), such as pages for kernel code.


